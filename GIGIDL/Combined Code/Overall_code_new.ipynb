{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#import imutils # Package of convenience functions\n",
    "#from skimage import io\n",
    "#import matplotlib.pyplot as plt\n",
    "#import requests\n",
    "#import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Importing necessary libraries for creating model\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import cv2 # importing open CV library\n",
    "import dlib   # For frontal face identity\n",
    "from PIL import Image\n",
    "import csv\n",
    "import face_recognition # importing face recognition library\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sys\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Unpack and extract images paths\n",
    "\n",
    "# Create a ZipFile Object and load sample.zip in it\n",
    "with ZipFile('../../OUI/OUI.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file \n",
    "   zipObj.extractall('../OUI_unarchive')\n",
    "\n",
    "images = []\n",
    "if len(next(os.walk('../OUI_unarchive/OUI/'))[1]) == 0: #case when images are in one folder\n",
    "    for image in os.listdir('../OUI_unarchive/OUI/'): \n",
    "        if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "            images.append('../OUI_unarchive/OUI/' + image)\n",
    "else: #case when images are in several folders\n",
    "    for path in ['../OUI_unarchive/OUI/' + next(os.walk('../OUI_unarchive/OUI/'))[1][n] for n in range(len(next(os.walk('../OUI_unarchive/OUI/'))[1]))]:\n",
    "        for image in os.listdir(path+'/'): \n",
    "            if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "                images.append(path+'/' + image)\n",
    "            \n",
    "print('Total number of images:', len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['female1.jpg', 'female2.jpg', 'female3.jpg', 'male1.jpg', 'male2.jpg', 'male3.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #############################################################################\n",
    "# loading the trained model and weights\n",
    "json_file = open('../Trained Model/model.json', 'r')     # Loading the jason file\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"../Trained Model/model.h5\")    # Loading the weights\n",
    "\n",
    "\n",
    "def detect_faces(image):                    # Create a face detector\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    detected_faces = face_detector(image, 1)    # Run detector and get bounding boxes of the faces on image\n",
    "    face_frames = [(x.left(), x.top(),\n",
    "                    x.right(), x.bottom()) for x in detected_faces]  # To identify the frame size\n",
    "    return face_frames\n",
    "\n",
    "\n",
    "def resize_im(image, hight, width):          # Resizing the image\n",
    "    resized_im = image.resize((hight, width))\n",
    "    return resized_im\n",
    "\n",
    "\n",
    "def reshape(numpy_array):            # Reshape the image\n",
    "    d = np.stack(numpy_array)\n",
    "    reshaped = d.reshape(1, d.size)\n",
    "    return reshaped\n",
    "\n",
    "\n",
    "def GIGIDL(image_path):\n",
    "    f = open(\"../storage.csv\", \"w\")\n",
    "    img= cv2.imread(image_path)\n",
    "    detected_faces = detect_faces(img)\n",
    "    for n, face_rect in enumerate(detected_faces):\n",
    "        fa = Image.fromarray(img).crop(face_rect)   # Cropping the face or faces\n",
    "        s = np.array(resize_im(fa, 100,100))\n",
    "        c = cv2.cvtColor(s, cv2.COLOR_BGR2GRAY)    # Converting the image\n",
    "        re_data = reshape(c)\n",
    "        np.savetxt(f, re_data, delimiter=\",\", fmt = '%d')  # Save the converted image data\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()    # Need to kill the image window\n",
    "    #reading the faces from the temp file\n",
    "    data = pd.read_csv('../storage.csv', header = None)\n",
    "    df_x = data.iloc[:,0:].values.reshape(len(data),100,100,1)   # Creating the requird formate\n",
    "    f_x = np.array(df_x)  # Need to convert as a array\n",
    "    loaded_model.compile(loss='categorical_crossentropy',optimizer = 'adadelta', metrics = ['accuracy'])\n",
    "    prob = np.asmatrix(loaded_model.predict(f_x))\n",
    "    if prob[0,0] > prob[0,1]:\n",
    "             gender= 'f'\n",
    "    if prob[0,0] < prob[0,1]:\n",
    "             gender='m'\n",
    "    return gender\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OUI.csv', 'w', newline='') as myfile:             # Here output written in the file\n",
    "    wr = csv.writer(myfile,quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(['Image_name','Pred_Gender'])\n",
    "\n",
    "    for imagelocation in images:                        # Get the images location\n",
    "            imageInfo = imagelocation.split('/')\n",
    "            image =imageInfo[-1].split('.')\n",
    "            #imageName = imageInfo[-2]+'/'+'.'.join(image[-3:])\n",
    "            imageName = imagelocation\n",
    "            try:\n",
    "                GIGIDL_gender=GIGIDL(imagelocation)   # return the predicted gender\n",
    "                print(imageName, GIGIDL_gender)\n",
    "                wr = csv.writer(myfile,quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow([imageName,GIGIDL_gender])\n",
    "            except:\n",
    "                wr = csv.writer(myfile,quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow([imageName,'u'])   #if there is an error in returning gender , write undefined\n",
    "                print(\"Oops!\",sys.exc_info()[0],\"occured.\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_ext(input_dir,output_dir):\n",
    "    # Create a ZipFile Object and load sample.zip in it\n",
    "    with ZipFile(input_dir, 'r') as zipObj:\n",
    "    # Extract all the contents of zip file \n",
    "        zipObj.extractall(output_dir)\n",
    "    files=[output_dir+'/'+name for name in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, name))]\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, sep=\"\\t\")  #load each file as dataframe\n",
    "        df= df.append(data, ignore_index = True)\n",
    "    df= df.astype(str)\n",
    "    df['Image_name']=df['user_id']+'/'+ df['face_id']+'.'+df['original_image'] # make Image name similar to the one in the image path\n",
    "    df= df[['Image_name','gender']] # keep only gender and imagename\n",
    "    return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= annotation_ext('../../OUI/OUI_annotations.zip','../OUI_annotations')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precision, recall, F1_score\n",
    "#read the result_file\n",
    "df_pred=pd.read_csv('/Users/nadabeili/Desktop/Improved-Gender-Identifier/OUI.csv')\n",
    "result_data= pd.merge(result,df_pred, how= 'inner', on='Image_name')\n",
    "result_data.to_csv('../all_result.csv')\n",
    "result_data.dropna(inplace=True)\n",
    "# True values\n",
    "y_true = result_data['gender']\n",
    "# Predicted values\n",
    "y_pred = result_data['Pred_Gender']\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "# Print the precision and recall, among other metrics\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "#printing the metrics\n",
    "metrics_dict=classification_report(y_true, y_pred,output_dict=True)\n",
    "\n",
    "#precision:\n",
    "print('Precision:',round(metrics_dict['weighted avg']['precision'],4))\n",
    "#Recall\n",
    "print('Recall:',round(metrics_dict['weighted avg']['recall'],4))\n",
    "#F1-score\n",
    "print('F1-score:',round(metrics_dict['weighted avg']['f1-score'],4))\n",
    "#accuracy\n",
    "print('Accuracy:',round(metrics_dict['accuracy'],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
