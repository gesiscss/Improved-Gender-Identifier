{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "from deepface.extendedmodels import  Gender\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "from urllib.request import urlopen\n",
    "from scipy.io import loadmat\n",
    "import csv\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables to be defined\n",
    "dataset='scholar'\n",
    "data_path='../Data/scholar/scholar_images.zip'\n",
    "output_path= '../Data/scholar/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data extraction:\n",
    "def extract_data(dataset, data_path, output_path):\n",
    "    d={'imdb':'', 'wiki':'gz'}\n",
    "    if dataset=='imdb'or dataset=='wiki':\n",
    "        tar = tarfile.open(data_path,\"r:\"+ d[dataset])\n",
    "        tar.extractall(output_path)\n",
    "        tar.close()\n",
    "    else:\n",
    "        with ZipFile(data_path, 'r') as zipObj:\n",
    "        # Extract all the contents of zip file \n",
    "            zipObj.extractall(output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the data is one of 5 remaining, use this code to extract image_path\n",
    "extract_data(dataset, data_path, output_path)\n",
    "images=[]\n",
    "if len(next(os.walk(output_path))[1]) == 0: #case when images are in one folder\n",
    "        for image in os.listdir(output_path): \n",
    "            if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "                images.append(output_path + image)\n",
    "else: #case when images are in several folders\n",
    "        for path in [output_path + next(os.walk(output_path))[1][n] for n in range(len(next(os.walk(output_path))[1]))]:\n",
    "            if len(next(os.walk(path))[1]) == 0:\n",
    "                for image in os.listdir(path+'/'): \n",
    "                    if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "                           images.append(path+'/' + image)\n",
    "            else:\n",
    "                for sub_path in [path+'/' + next(os.walk(path))[1][n] for n in range(len(next(os.walk(path))[1]))]:\n",
    "                    for image in os.listdir(sub_path+'/'): \n",
    "                        if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "                               images.append(sub_path+'/' +image)\n",
    "print('Total number of images:', len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the gender model from deepface\n",
    "models = {}\n",
    "models[\"gender\"] = Gender.loadModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepface(img_path):\n",
    "    deepface_pred = DeepFace.analyze(img_path, actions=['gender'] ,models=models,enforce_detection= True)\n",
    "    if deepface_pred['gender']=='Woman':\n",
    "        gender='f'\n",
    "    else:\n",
    "        gender='m'\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path+dataset+'.csv', 'w', newline='') as myfile:             # Here output written in the file\n",
    "        wr = csv.writer(myfile,quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Image_name','Pred_Gender'])\n",
    "        for imagelocation in images:                        # Get the images location\n",
    "                try:\n",
    "                    deepface_gender=deepface(imagelocation)   # return the predicted gender\n",
    "                    wr = csv.writer(myfile,quoting=csv.QUOTE_ALL)\n",
    "                    wr.writerow([imagelocation,deepface_gender])\n",
    "                except:\n",
    "                    wr = csv.writer(myfile,quoting=csv.QUOTE_ALL)\n",
    "                    wr.writerow([imagelocation,'u'])   #if there is an error in returning gender , write undefined\n",
    "                    print(\"Oops!\",sys.exc_info()[0],\"occured.\")\n",
    "                    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset== 'twitter':\n",
    "    df_twitter=pd.read_csv(output_path+dataset+'.csv')\n",
    "    df_twitter['Image_name'] = df_twitter['Image_name'].apply(lambda x: x.split('/')[-1]) #removing the folder names\n",
    "    df_twitter['Image_name']=df_twitter['Image_name'].apply(lambda x: x.split('.')[0])\n",
    "    df_twitter.to_csv(output_path+dataset+'.csv', index= False)\n",
    "if dataset=='Gender_Shade':\n",
    "    df_shade=pd.read_csv(output_path+dataset+'.csv')\n",
    "    df_shade['Image_name']= df_shade['Image_name'].apply(lambda x: x.split('/')[-1])\n",
    "    df_shade.to_csv(output_path+dataset+'.csv', index= False)\n",
    "if dataset=='OUI'or dataset=='wiki' or dataset=='imdb':\n",
    "    df_oui=pd.read_csv(output_path+dataset+'.csv')\n",
    "    df_oui['Image_name']= df_oui['Image_name'].apply(lambda x: x.split('/'))\n",
    "    df_oui['Image_name']=df_oui['Image_name'].apply(lambda x: x[-2]+'/'+x[-1])\n",
    "    df_oui['Image_name']=df_oui['Image_name'].apply(lambda x: re.sub('landmark_aligned_face.', '', x) ) \n",
    "    df_oui.to_csv(output_path+dataset+'.csv', index= False)\n",
    "else:\n",
    "    df_oui=pd.read_csv(output_path+dataset+'.csv')\n",
    "    df_oui['Image_name']= df_oui['Image_name'].apply(lambda x: x.split('/')[-1])\n",
    "    #df_oui['Image_name']=df_oui['Image_name'].apply(lambda x: x[-2]+'/'+x[-1])\n",
    "    df_oui['Image_name']=df_oui['Image_name'].apply(lambda x: re.sub('landmark_aligned_face.', '', x) ) \n",
    "    df_oui.to_csv(output_path+dataset+'.csv', index= False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oui.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract  annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Gender_shade dataset\n",
    "shade_annotation= pd.read_csv('../Data/PPB-2017-metadata.csv')\n",
    "shade_annotation= shade_annotation[['filename','gender']]\n",
    "shade_annotation.columns = ['Image_name', 'true_gender']\n",
    "shade_annotation['true_gender']= shade_annotation['true_gender'].apply(lambda x: 'f' if x=='Female' else 'm')\n",
    "print(shade_annotation.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',shade_annotation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For TWITTER dataset ###\n",
    "# 1)Extract the annotations\n",
    "#extract_data(dataset, '../Data/twitter/_a_results32langs.zip', '../Data/twitter/_a_results32langs/')\n",
    "###\n",
    "twitter_annotation = pd.DataFrame()\n",
    "meta_path = '../Data/twitter/_a_results32langs/'\n",
    "for file in os.listdir(meta_path):\n",
    "    df = pd.read_csv(meta_path + file)\n",
    "    twitter_annotation = twitter_annotation.append(df)\n",
    "    \n",
    "twitter_annotation.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "## FOR TWITTER ##\n",
    "twitter_annotation=twitter_annotation[['temp_file','indicated_gender','indicated_gender:confidence']]\n",
    "twitter_annotation.rename(columns={'temp_file':'Image_name', 'indicated_gender': 'true_gender'}, inplace=True)\n",
    "twitter_annotation = twitter_annotation[twitter_annotation['indicated_gender:confidence'] >= 0.8][(twitter_annotation['true_gender']=='male') | (twitter_annotation['true_gender']=='female') | (twitter_annotation['true_gender']=='orga')]\n",
    "twitter_annotation['true_gender'] = twitter_annotation['true_gender'].apply(lambda x: \"f\" if x == 'female' else (\"m\" if x=='male' else 'u') ) \n",
    "####\n",
    "print(twitter_annotation.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',twitter_annotation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for OUI Dataset\n",
    "def oui_annotation_extraction(annotation_path,annotation_output_path):\n",
    "    extract_data(dataset, annotation_path, annotation_output_path)  #unzip the file \n",
    "    files=[annotation_output_path+'/'+name for name in os.listdir(annotation_output_path) if os.path.isfile(os.path.join(annotation_output_path, name))]\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, sep=\"\\t\")  #load each file as dataframe\n",
    "        df= df.append(data, ignore_index = True)\n",
    "    df= df.astype(str)\n",
    "    df['Image_name']=df['user_id']+'/'+ df['face_id']+'.'+df['original_image'] # make Image name similar to the one in the image path\n",
    "    df= df[['Image_name','gender']] # keep only gender and imagename\n",
    "    df=df.rename(columns={\"gender\": \"true_gender\"})\n",
    "    df['true_gender']=df['true_gender'].apply(lambda x: 'u' if x=='nan' else x)\n",
    "    return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oui_annotation= oui_annotation_extraction('../Data/OUI_annotations.zip','../Data/OUI_annotations')\n",
    "print(oui_annotation.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',oui_annotation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for subgroups:\n",
    "sub_annotation= oui_annotation_extraction('../Data/OUI_annotations.zip','../Data/OUI_annotations')\n",
    "sub_annotation['Image_name']= sub_annotation['Image_name'].apply(lambda x: x.split('/')[-1])\n",
    "print(sub_annotation.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',sub_annotation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scholar_anno= pd.read_csv('../Data/scholar/meta.csv')\n",
    "scholar_anno=scholar_anno.rename(columns={\"Image_path\": \"Image_name\", \"Gender\": \"true_gender\"})\n",
    "scholar_anno['Image_name']= scholar_anno['Image_name'].apply(lambda x: x.split('/')[-1])\n",
    "scholar_anno['true_gender']= scholar_anno['true_gender'].apply(lambda x: x.lower())\n",
    "\n",
    "print(scholar_anno.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',scholar_anno.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For IMDB and wiki datasets\n",
    "############################\n",
    "### for .mat file for IMDB ###\n",
    "def get_names(x):\n",
    "    if len(x)>0:\n",
    "        return x[0]\n",
    "    else:\n",
    "        return ''\n",
    "### for .mat file for imdb and wiki ###\n",
    "if dataset == 'imdb' or dataset == 'wiki':\n",
    "    path_to_meta = output_path+'imdb_crop'+ '/' + dataset + \".mat\"\n",
    "    mat = loadmat(path_to_meta)  # load mat-file\n",
    "    mdata = mat[dataset]  # variable in mat file\n",
    "    mdtype = mdata.dtype\n",
    "    ndata = {n: mdata[n][0, 0] for n in mdtype.names}\n",
    "    columns = [n for n, v in ndata.items()]# if v.size == ndata['numIntervals']] \n",
    "    full_path = [mdata['full_path'][0,0][0][n][0] for n in range(len(mdata['full_path'][0,0][0]))]\n",
    "    gender = mdata['gender'][0,0][0]\n",
    "    #gender_dic= {1:'m',0:'f'}\n",
    "    # gender=list(map(gender_dic.get, gender))\n",
    "    \n",
    "    if dataset == 'imdb':\n",
    "        imdb_annotation = pd.DataFrame({ \"Image_name\":full_path, \"true_gender\":gender})\n",
    "        imdb_annotation['true_gender'] = imdb_annotation['true_gender'].apply(lambda x: \"f\" if x == 0 else \"m\")\n",
    "    elif dataset=='wiki':\n",
    "        wiki_annotation = pd.DataFrame({ \"Image_name\":full_path, \"true_gender\":gender})\n",
    "        wiki_annotation['true_gender'] = wiki_annotation['true_gender'].apply(lambda x: \"f\" if x == 0 else \"m\")\n",
    "\n",
    "print(imdb_annotation.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',imdb_annotation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precision, recall, F1_score\n",
    "## set the value of df_annotation (df_annotation= dataset's annotation file)\n",
    "df_annotation= scholar_anno\n",
    "#read the result_file\n",
    "df_pred=pd.read_csv(output_path+dataset+'.csv')\n",
    "\n",
    "##merge the annotation with the model prediction\n",
    "result_data= pd.merge(df_annotation,df_pred, how= 'inner', on='Image_name')\n",
    "result_data.to_csv(output_path+'/all_result_'+dataset+'.csv')\n",
    "\n",
    "#remove the undifined gender\n",
    "result_data= result_data[result_data.Pred_Gender !='u']\n",
    "result_data= result_data[result_data.true_gender !='u']\n",
    "\n",
    "# True values\n",
    "y_true = result_data['true_gender']\n",
    "# Predicted values\n",
    "y_pred = result_data['Pred_Gender']\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "# Print the precision and recall, among other metrics\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "#printing the metrics\n",
    "metrics_dict=classification_report(y_true, y_pred,output_dict=True)\n",
    "\n",
    "#precision:\n",
    "print('Precision:',round(metrics_dict['weighted avg']['precision'],4))\n",
    "#Recall\n",
    "print('Recall:',round(metrics_dict['weighted avg']['recall'],4))\n",
    "#F1-score\n",
    "print('F1-score:',round(metrics_dict['weighted avg']['f1-score'],4))\n",
    "#accuracy\n",
    "print('Accuracy:',round(metrics_dict['accuracy'],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
