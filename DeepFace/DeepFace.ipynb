{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "from deepface.extendedmodels import  Gender\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "from urllib.request import urlopen\n",
    "from scipy.io import loadmat\n",
    "import csv\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables to be defined\n",
    "dataset='imdb'\n",
    "data_path='../Data/imdb_crop.tar'\n",
    "output_path= '../Data/imdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data extraction:\n",
    "def extract_data(dataset, data_path, output_path):\n",
    "    d={'imdb':'', 'wiki':'gz'}\n",
    "    if dataset=='imdb'or dataset=='wiki':\n",
    "        tar = tarfile.open(data_path,\"r:\"+ d[dataset])\n",
    "        tar.extractall(output_path)\n",
    "        tar.close()\n",
    "    else:\n",
    "        with ZipFile(data_path, 'r') as zipObj:\n",
    "        # Extract all the contents of zip file \n",
    "            zipObj.extractall(output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 460723\n"
     ]
    }
   ],
   "source": [
    "#if the data is one of 5 remaining, use this code to extract image_path\n",
    "#extract_data(dataset, data_path, output_path)\n",
    "images=[]\n",
    "if len(next(os.walk(output_path))[1]) == 0: #case when images are in one folder\n",
    "        for image in os.listdir(output_path): \n",
    "            if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "                images.append(output_path + image)\n",
    "else: #case when images are in several folders\n",
    "        for path in [output_path + next(os.walk(output_path))[1][n] for n in range(len(next(os.walk(output_path))[1]))]:\n",
    "            if len(next(os.walk(path))[1]) == 0:\n",
    "                for image in os.listdir(path+'/'): \n",
    "                    if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "                           images.append(path+'/' + image)\n",
    "            else:\n",
    "                for sub_path in [path+'/' + next(os.walk(path))[1][n] for n in range(len(next(os.walk(path))[1]))]:\n",
    "                    for image in os.listdir(sub_path+'/'): \n",
    "                        if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "                               images.append(sub_path+'/' +image)\n",
    "print('Total number of images:', len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the gender model from deepface\n",
    "models = {}\n",
    "models[\"gender\"] = Gender.loadModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepface(img_path):\n",
    "    deepface_pred = DeepFace.analyze(img_path, actions=['gender'] ,models=models,enforce_detection= True)\n",
    "    if deepface_pred['gender']=='Woman':\n",
    "        gender='f'\n",
    "    else:\n",
    "        gender='m'\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: gender: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:01<?, ?it/s]\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n",
      "Oops! <class 'ValueError'> occured.\n",
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: gender: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n",
      "Oops! <class 'ValueError'> occured.\n",
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: gender: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: gender: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: gender: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n",
      "Oops! <class 'ValueError'> occured.\n",
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: gender: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Finding actions:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Action: gender:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[A\n",
      "Analyzing:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions to do:  ['gender']\n",
      "already built gender model is passed\n",
      "Oops! <class 'ValueError'> occured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(output_path+dataset+'.csv', 'w', newline='') as myfile:             # Here output written in the file\n",
    "        wr = csv.writer(myfile,quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(['Image_name','Pred_Gender'])\n",
    "        for imagelocation in images[:10]:                        # Get the images location\n",
    "                try:\n",
    "                    deepface_gender=deepface(imagelocation)   # return the predicted gender\n",
    "                    wr = csv.writer(myfile,quoting=csv.QUOTE_ALL)\n",
    "                    wr.writerow([imagelocation,deepface_gender])\n",
    "                except:\n",
    "                    wr = csv.writer(myfile,quoting=csv.QUOTE_ALL)\n",
    "                    wr.writerow([imagelocation,'u'])   #if there is an error in returning gender , write undefined\n",
    "                    print(\"Oops!\",sys.exc_info()[0],\"occured.\")\n",
    "                    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset== 'twitter':\n",
    "    df_twitter=pd.read_csv(output_path+dataset+'.csv')\n",
    "    df_twitter['Image_name'] = df_twitter['Image_name'].apply(lambda x: x.split('/')[-1]) #removing the folder names\n",
    "    df_twitter['Image_name']=df_twitter['Image_name'].apply(lambda x: x.split('.')[0])\n",
    "    df_twitter.to_csv(output_path+dataset+'.csv', index= False)\n",
    "if dataset=='Gender_Shade':\n",
    "    df_shade=pd.read_csv(output_path+dataset+'.csv')\n",
    "    df_shade['Image_name']= df_shade['Image_name'].apply(lambda x: x.split('/')[-1])\n",
    "    df_shade.to_csv(output_path+dataset+'.csv', index= False)\n",
    "if dataset=='OUI'or dataset=='wiki' or dataset=='imdb':\n",
    "    df_oui=pd.read_csv(output_path+dataset+'.csv')\n",
    "    df_oui['Image_name']= df_oui['Image_name'].apply(lambda x: x.split('/'))\n",
    "    df_oui['Image_name']=df_oui['Image_name'].apply(lambda x: x[-2]+'/'+x[-1])\n",
    "    df_oui['Image_name']=df_oui['Image_name'].apply(lambda x: re.sub('landmark_aligned_face.', '', x) ) \n",
    "    df_oui.to_csv(output_path+dataset+'.csv', index= False)\n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract  annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Image_name true_gender\n",
      "0  0001_1_f_FL.jpg           f\n",
      "1  0002_1_f_FL.jpg           f \n",
      "\n",
      "the shape of the annotation dataframe is (1270, 2)\n"
     ]
    }
   ],
   "source": [
    "## For Gender_shade dataset\n",
    "shade_annotation= pd.read_csv('../Data/PPB-2017-metadata.csv')\n",
    "shade_annotation= shade_annotation[['filename','gender']]\n",
    "shade_annotation.columns = ['Image_name', 'true_gender']\n",
    "shade_annotation['true_gender']= shade_annotation['true_gender'].apply(lambda x: 'f' if x=='Female' else 'm')\n",
    "print(shade_annotation.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',shade_annotation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For TWITTER dataset ###\n",
    "# 1)Extract the annotations\n",
    "#extract_data(dataset, '../Data/twitter/_a_results32langs.zip', '../Data/twitter/_a_results32langs/')\n",
    "###\n",
    "twitter_annotation = pd.DataFrame()\n",
    "meta_path = '../Data/twitter/_a_results32langs/'\n",
    "for file in os.listdir(meta_path):\n",
    "    df = pd.read_csv(meta_path + file)\n",
    "    twitter_annotation = twitter_annotation.append(df)\n",
    "    \n",
    "twitter_annotation.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "## FOR TWITTER ##\n",
    "twitter_annotation=twitter_annotation[['temp_file','indicated_gender','indicated_gender:confidence']]\n",
    "twitter_annotation.rename(columns={'temp_file':'Image_name', 'indicated_gender': 'true_gender'}, inplace=True)\n",
    "twitter_annotation = twitter_annotation[twitter_annotation['indicated_gender:confidence'] >= 0.8][(twitter_annotation['true_gender']=='male') | (twitter_annotation['true_gender']=='female') | (twitter_annotation['true_gender']=='orga')]\n",
    "twitter_annotation['true_gender'] = twitter_annotation['true_gender'].apply(lambda x: \"f\" if x == 'female' else (\"m\" if x=='male' else 'u') ) \n",
    "####\n",
    "print(twitter_annotation.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',twitter_annotation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for OUI Dataset\n",
    "def oui_annotation_extraction(annotation_path,annotation_output_path):\n",
    "    extract_data(dataset, annotation_path, annotation_output_path)  #unzip the file \n",
    "    files=[annotation_output_path+'/'+name for name in os.listdir(annotation_output_path) if os.path.isfile(os.path.join(annotation_output_path, name))]\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, sep=\"\\t\")  #load each file as dataframe\n",
    "        df= df.append(data, ignore_index = True)\n",
    "    df= df.astype(str)\n",
    "    df['Image_name']=df['user_id']+'/'+ df['face_id']+'.'+df['original_image'] # make Image name similar to the one in the image path\n",
    "    df= df[['Image_name','gender']] # keep only gender and imagename\n",
    "    df=df.rename(columns={\"gender\": \"true_gender\"})\n",
    "    df['true_gender']=df['true_gender'].apply(lambda x: 'u' if x=='nan' else x)\n",
    "    return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oui_annotation= oui_annotation_extraction('../Data/OUI_annotations.zip','../Data/OUI_annotations')\n",
    "print(oui_annotation.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',oui_annotation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Image_name true_gender\n",
      "0   01/nm0000001_rm124825600_1899-5-10_1968.jpg           m\n",
      "1  01/nm0000001_rm3343756032_1899-5-10_1970.jpg           m \n",
      "\n",
      "the shape of the annotation dataframe is (460723, 2)\n"
     ]
    }
   ],
   "source": [
    "## For IMDB and wiki datasets\n",
    "############################\n",
    "### for .mat file for IMDB ###\n",
    "def get_names(x):\n",
    "    if len(x)>0:\n",
    "        return x[0]\n",
    "    else:\n",
    "        return ''\n",
    "### for .mat file for imdb and wiki ###\n",
    "if dataset == 'imdb' or dataset == 'wiki':\n",
    "    path_to_meta = output_path+'imdb_crop'+ '/' + dataset + \".mat\"\n",
    "    mat = loadmat(path_to_meta)  # load mat-file\n",
    "    mdata = mat[dataset]  # variable in mat file\n",
    "    mdtype = mdata.dtype\n",
    "    ndata = {n: mdata[n][0, 0] for n in mdtype.names}\n",
    "    columns = [n for n, v in ndata.items()]# if v.size == ndata['numIntervals']] \n",
    "    full_path = [mdata['full_path'][0,0][0][n][0] for n in range(len(mdata['full_path'][0,0][0]))]\n",
    "    gender = mdata['gender'][0,0][0]\n",
    "    #gender_dic= {1:'m',0:'f'}\n",
    "    # gender=list(map(gender_dic.get, gender))\n",
    "    \n",
    "    if dataset == 'imdb':\n",
    "        imdb_annotation = pd.DataFrame({ \"Image_name\":full_path, \"true_gender\":gender})\n",
    "        imdb_annotation['true_gender'] = imdb_annotation['true_gender'].apply(lambda x: \"f\" if x == 0 else \"m\")\n",
    "    elif dataset=='wiki':\n",
    "        wiki_annotation = pd.DataFrame({ \"Image_name\":full_path, \"true_gender\":gender})\n",
    "        wiki_annotation['true_gender'] = wiki_annotation['true_gender'].apply(lambda x: \"f\" if x == 0 else \"m\")\n",
    "\n",
    "print(imdb_annotation.head(2),'\\n')\n",
    "print('the shape of the annotation dataframe is',imdb_annotation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82728  33997]\n",
      " [ 22719 122456]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f     0.7845    0.7087    0.7447    116725\n",
      "           m     0.7827    0.8435    0.8120    145175\n",
      "\n",
      "    accuracy                         0.7834    261900\n",
      "   macro avg     0.7836    0.7761    0.7783    261900\n",
      "weighted avg     0.7835    0.7834    0.7820    261900\n",
      "\n",
      "Precision: 0.7835\n",
      "Recall: 0.7834\n",
      "F1-score: 0.782\n",
      "Accuracy: 0.7834\n"
     ]
    }
   ],
   "source": [
    "### Precision, recall, F1_score\n",
    "## set the value of df_annotation (df_annotation= dataset's annotation file)\n",
    "df_annotation= imdb_annotation\n",
    "#read the result_file\n",
    "df_pred=pd.read_csv(output_path+dataset+'.csv')\n",
    "\n",
    "##merge the annotation with the model prediction\n",
    "result_data= pd.merge(df_annotation,df_pred, how= 'inner', on='Image_name')\n",
    "result_data.to_csv(output_path+'/all_result_'+dataset+'.csv')\n",
    "\n",
    "#remove the undifined gender\n",
    "result_data= result_data[result_data.Pred_Gender !='u']\n",
    "\n",
    "# True values\n",
    "y_true = result_data['true_gender']\n",
    "# Predicted values\n",
    "y_pred = result_data['Pred_Gender']\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "# Print the precision and recall, among other metrics\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "#printing the metrics\n",
    "metrics_dict=classification_report(y_true, y_pred,output_dict=True)\n",
    "\n",
    "#precision:\n",
    "print('Precision:',round(metrics_dict['weighted avg']['precision'],4))\n",
    "#Recall\n",
    "print('Recall:',round(metrics_dict['weighted avg']['recall'],4))\n",
    "#F1-score\n",
    "print('F1-score:',round(metrics_dict['weighted avg']['f1-score'],4))\n",
    "#accuracy\n",
    "print('Accuracy:',round(metrics_dict['accuracy'],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>true_gender</th>\n",
       "      <th>Pred_Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461924</th>\n",
       "      <td>08/nm3994408_rm727691264_1989-12-29_2011.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461925</th>\n",
       "      <td>08/nm3994408_rm73386752_1989-12-29_2011.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461926</th>\n",
       "      <td>08/nm3994408_rm744468480_1989-12-29_2011.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461928</th>\n",
       "      <td>08/nm3994408_rm761245696_1989-12-29_2011.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461931</th>\n",
       "      <td>08/nm3994408_rm943369728_1989-12-29_2011.jpg</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Image_name true_gender Pred_Gender\n",
       "0        01/nm0000001_rm124825600_1899-5-10_1968.jpg           m           m\n",
       "1       01/nm0000001_rm3343756032_1899-5-10_1970.jpg           m           m\n",
       "2        01/nm0000001_rm577153792_1899-5-10_1968.jpg           m           m\n",
       "5       02/nm0000002_rm1075631616_1924-9-16_1991.jpg           f           f\n",
       "6       02/nm0000002_rm1346607872_1924-9-16_2004.jpg           f           f\n",
       "...                                              ...         ...         ...\n",
       "461924  08/nm3994408_rm727691264_1989-12-29_2011.jpg           f           m\n",
       "461925   08/nm3994408_rm73386752_1989-12-29_2011.jpg           f           f\n",
       "461926  08/nm3994408_rm744468480_1989-12-29_2011.jpg           f           m\n",
       "461928  08/nm3994408_rm761245696_1989-12-29_2011.jpg           f           f\n",
       "461931  08/nm3994408_rm943369728_1989-12-29_2011.jpg           f           f\n",
       "\n",
       "[261900 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
